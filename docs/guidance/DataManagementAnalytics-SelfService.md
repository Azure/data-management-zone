# Scaling and Self-Service in Data Management & Analytics Scenario

Efficient scaling within an enterprise data platform is a much-desired goal of many organizations and as business units should be enabled to build their own (data) solutions and applications that fulfill their requirements. However, achieving this goal is a challenge as many existing data platforms are not built around the core concepts of scalability and decentralized ownership. This is not only true from an architectural standpoint but also becomes clear when looking at the teams structure and ops model which underpin these data platforms.

## Introduction

Today, many enterprises have large data platform monoliths built around the concept of a single Azure Data Lake Gen2 account and sometimes a single storage container. In addition, a single Azure subscription is often used for all data platform related tasks and the concept of subscription level scaling is absent in most architectural patterns. This can hinder continued adoption of Azure if users run into any of the [well-know Azure subscription or service-level limitations](https://docs.microsoft.com/en-us/azure/azure-resource-manager/management/azure-subscription-service-limits). Even though some of the constraints are soft limits, hitting these can still have a significant impact within a data platform that should be avoided at best.

Also, many organizations compose their data platform architecture and teams around functional responsibilities, and pipeline stages which must be applied to the various data assets of an organization to make them consumable for downstrea teams. As a result, several specialized teams within a data platform own an orthogonal solution such as ingestion, cleansing, aggregation or serving. This organizational and architectural design leads to a dramatic loss of velocity, because of dependency on several teams. For example, when a data consumer at the serving layer requires new data assets to be onboarded or functional changes to be implemented for a specific data asset, then multiple steps must be executed in a set sequence. The steps may involve:

- The Data Consumer must submit a ticket to the functional teams being responsible for the respective pipeline stages.
- Synchronization is now required between the functional teams as new ingestion services will be required, which will lead to changes required in the data cleansing layer, which will lead to changes on the data aggregation layer, which will again cause changes to be implemented on the serving layer. In summary, all pipeline stages may be impacted by the requested changes and clear impact on the processing staged will not be visible to any of these teams as no one overviews the end-to-end lifecycle.
- In addition to the synchronization that is required between the various teams, the teams must design a very well-defined release plan in order to not impact existing consumers or pipelines. This dependency management further increases the management overhead.
- All teams included in the requested change are most likely no subject matter experts for the specific data asset. Hence, additional consultation may be required to understand new dataset features or parameter values.
- After applying all changes, the Data Consumer needs to be notified that the data asset is ready to be consumed.

If we now take into consideration that within a large organization there is not a single data consumer but thousands of data consumers, the process described above makes clear why velocity is heavily impacted by such an architectural and organizational pattern. The centralized teams quickly become a bottleneck for the business units, which will ultimately result in slower innovations on the platform, limited effectiveness of data consumers and possibly even to a situation where individual business units decide to build their own data platform.

## Methods of scaling in the Data Management & Analytics Scenario

![Data Management & Analytics Scenario - Multiple Data Landing Zone Pattern](/docs/images/MultipleLandingZones.png)

Data Management & Analytics Scenario (DMA) uses two core concepts to address the scaling challenges mentioned in the [introduction](#introduction):

- Scaling through the concept of Data Landing Zones.
- Scaling through the concept of Data Product or Data Integrations to enable distributed and decentralized data ownership.

The following paragraphs will elaborate on these core concepts and will also describe how self-service can be enabled for Data Products.

### Scaling with Data Landing Zones

Data Management & Analytics Scenario is centred around the concepts of Data Management Zone and Data Landing Zone. Each of these artifacts should land in a separate Azure subscription to allow for clear separation of duties, to follow the least privilege principal and to partially address the first issue mentioned in the [introduction](#introduction) around subscription scale issues. Hence, the minimal setup of Data Management & Analytics Scenario consists of a single Data Management Zone and a single Data Landing Zone.

For large-scale data platform deployments, a single Data Landing Zone and hence a single subscription will not be sufficient, especially if we consider that companies build these platforms and make the respective investments to consistently and efficiently scale their data and analytics efforts in the upcoming years. Therefore, to fully overcome the subscription-level limitations and embrace the "subscription as scale unit" concept from [Enterprise-Scale Landing Zones](https://github.com/Azure/Enterprise-Scale), ESA allows an institution to further increase the data platform footprint by adding additional Data Landing Zones to the architecture. Furthermore, this also addresses the concern of a single Azure Data Lake Gen2 being used for a whole company as each Data Landing Zone comes with a set of three Data Lakes. Ultimately, this leads to a distribution of projects and activities of multiple domains across more than one Azure subscription, allowing for greater scalibility.

The question of how many Data Landing Zones an organization requires should be discussed and defined upfront before adopting the ESA prescriptive architectural pattern. This is considered to be one of the most important design decisions, because it lays the foundation for an effective and efficient data platform. When done right, it will prevent enterprises from ending up in a migration project of data products and data assets from one Data Landing Zone to another and will allow an effective and consistent scaling of any big data and analytics efforts for the upcoming years.

The following factors should be considered when deciding about how many Data Landing Zones should be deployed:

- *Data Domains*: What data domains does the organization encompass and which data domains will land on the data platform? What is the size of these individual data domains?
- *Cost allocation*: Are shared services like storage accounts paid centrally or do these need to be split by business unit or domain?
- *Location*: In which Azure Regions will the organization deploy their data platform? Will the platform be hosted in a single region or will it span across multiple regions? Are there data residency requirements that need to be taken into account?
- *Data classifications and highly confidential data*: What data classifications exist within the organization? Does the organization have datasets that are classified as highly confidential and do these datasets require special treatment in form of just in time access, customer managed keys (CMK), fine grained network controls or additional encryption being enforced? May these additional security mechanisms even impact usability of the data platform and data product development?
- *Other legal or security implications*: Are there any other legislations or security requirements that an organization needs to comply with that justify logical and/or physical separation of data?

Considering all these factors, an enterprise should target no more than 15 Data Landing Zones as there is also some management overhead attached to each Data Landing Zone.

It is important to emphasize that Data Landing Zones are not creating data silos within an organization, as the recommended network setup in ESA enables secure and in-place data sharing across Landing Zones and therefore enables innovation across data domains and business units. Please read the [network design guidance](/docs/guidance/DataManagementAnalytics-NetworkArchitecture.md) to find out more about how this is achieved. The same is true for the identity layer. Since a single Azure AD tenant is recommended to be used, identities can be granted access to data assets within multiple Data Landing Zones. For the actual authorization process of users and identities to data assets it is recommended to leverage Azure Active Directory Entitlement Management and Access Packages.

Lastly, it needs to be highlighted that the prescriptive ESA architecture and the concept of Data Landing Zones allows corporations to naturally increase the size of their data platform over time. Additional Data Landing Zones can be added in a phased approach and customers are not forced to start with a multi-Data Landing Zone setup right from the start. When adopting the pattern, companies should start prioritizing few Data Landing Zones as well as Data Products that should land inside them respectively, to make sure that the adoption of ESA is successful.

### Scaling with Data Products

Within a Data Landing Zone, the Data Management & Analytics Scenario allows organizations scale through the concept of Data Integrations and Data Products. A Data Product is a unit or component of the data architecture that encapsulates functionality for making read-optimized datasets available for consumption by other data products. In the Azure context, a Data Product is an environment in form of resource group that allows cross-functional teams to implement data solutions and workloads on the platform. The associated team takes care of the end-to-end lifecycle of their data solution including ingest (only for Data Integration), cleansing, aggregation and serving tasks for a particular data-domain, sub-domain, dataset or project.

A Data Integration pattern is a special kind of Data Product that is mainly concerned with the integration of data assets from source systems outside of the data platform onto a Data Landing Zone. These consistent data integration implementations reduce the impact on the transactional systems and allow multiple Data Product teams to consume the same dataset version without being concerned about the integration and without having to repeat the integration task.
Data Products on the other hand are consuming one or multiple data assets within the same Data Landing Zone or across multiple Data Landing Zones to generate new data assets, insights or business value. The resulting data assets may again be shared with other Data Product teams to enhance the value being created within the business even further.

With the Data Integration concept, Data Management & Analytics Scenario addresses the data integration and responsibility issue mentioned in the [introduction](#introduction). Instead of having an architectural design build around monolithic functional responsibilities for the ingestion of tables and integration of source systems, the reference design is pivoting the design towards a distributed, data domains driven architecture, where cross functional teams take over the end-to-end functional responsibility and ownership for the respective data scope. In summary, this means that instead of having a centralized technical stack and team being responsible for each and every orthogonal solution of the data processing workflow, we are distributing the end-to-end responsibility from ingestion to the serving layer for data domains or sub-domains across multiple autonomously working cross-functional Data Integration teams. The Data Integration teams own a domain or sub-domain capability and must be encouraged to serve datasets for access by any team for any purpose or project they may be working on.

This architectural paradigm shift ultimately leads to an increased velocity within the data platform as data consumers do no longer have to rely on a set of centralized teams or have to fight for prioritization of the requested changes. As smaller teams take ownership of the end-to-end integration workflow, the feedback loop between data provider and data consumer is much shorter and therefore allows for much quicker prioritization, development cycles and a more agile development process. Additionally, complex synchronization processes and release plans between teams are no longer required as the cross-functional Data Integration team has full visibility of the end-to-end technical stack as well as any implications that may arise due to the implemented changes. The team can apply software engineering practices to run unit and integration tests to minimize overall impact on consumers.

In an ideal world, the data integration would be owned by the same team that owns the source systems. But the team should in general not only consist of data engineers that work on the source systems, but also of subject matter experts (SMEs) for these datasets, cloud engineers and data product owners. Such a cross-functional team setup reduces the communication required to teams outside and will be essential when developing the complete stack from infrastructure to actual data pipelines.

Integrated datasets from source systems become the foundation of the data platform and will enable Data Product teams to further innovate on top of the business fact tables to eventually improve decision making and optimize business processes. Both Data Integration and Data Product teams should offer SLAs to consumers and ensure hat agreements are met. These SLAs can be related to data quality, timeliness, error rates, uptime and other tasks.

### Summary

The sections above are summarizing the scaling mechanisms within Data Management & Analytics Scenario that organizations can use to grow their data estate within Azure over time without running into well-known technical limitations. Both scaling mechanisms are helping to overcome different technical complexities and can be used in an efficient and simple way.

In the previous section, we discussed strategies to enable scale; improve agility; and reduce development lifecycle within Data Integration and Data Product environments. However, this will only be possible if teams have appropriate access which enables self-serve. How this can be achieved will be discussed in the following section.

## Enabling Self-service for Data Products in Data Management & Analytics Scenario

Self-service is one of the key building blocks of Data Management & Analytics Scenario to allow agility, quick development and sharing of Data Products within the respective Data Landing Zones of an organization. Data Product teams are usually the ones demanding such capabilities whereas central IT teams usually have their concerns when enabling business units to deploy their own services, features and application code.

However, as an organization scales beyond a handful of Data Products and projects, it will become impossible for a centralized team to address all requests in a short and timely manner. Hence, the only solution to this is self-service, where support can still be requested by the Data Product teams to overcome technical challenges, to troubleshoot connectivity issues or other kinds of problems. To address the concerns of both teams, we will look at a number of aspects that will eventually enable self-service in a secure and controlled way without loosing control over the overall compliance of the Data Platform environment.

### Azure Policies

Azure Policy should be the core instrument of the Azure (Data) Platform team to ensure compliance of resources within the Data Management Zone, Data Landing Zones as well as other landing zones within the organization's tenant. This platform feature should be used to introduce guardrails and enforce adherence to the overall approved service configuration within the respective management group scope. The platform teams can use Azure Policy to, for example, enforce private endpoints for any storage accounts that are being hosted within the data platform environment or enforce TLS 1.2 encryption in transit for any connections being made to the storage accounts. When done right, this will prohibit any Data Product teams from hosting services in an incompliant state within the respective tenant scope.

The responsible IT teams should use this platform feature to address their security and compliance concerns and open up for a self-service approach within (Data) Landing Zones. [Please follow this link](/docs/guidance/DataManagementAnalytics-Policies.md) to read more about the Azure policies that are recommended for the ESA data platform environment.

### Azure RBAC assignments

In order to develop, deliver and serve data products autonomously within the data platform, Data Product and Data Integration teams require few access rights within the Azure environment. Before going through the respective RBAC requirements it must be highlighted that different access models should be used for the development and higher environments. Also, security groups should be used wherever possible to reduce the number of role assignments and to simplify the management and review process of RBAC rights. This is critical, due to the [limited number of role assignments that can be created per subscription](https://docs.microsoft.com/en-us/azure/azure-resource-manager/management/azure-subscription-service-limits#azure-rbac-limits).

The development environment should be allowed to be accessed by the development team and their respective user identities to enable them to iterate more quickly, learn about certain capabilities within Azure services and troubleshoot issues effectively. Access to a development environment will help when developing or enhancing the infrastructure as code (IaC) as well as other code artifacts. Once an implementation within the development environment works as expected, it can be rolled out continuously to the higher environments. Higher environments, such as test and prod, should be locked off for the Data Product team. Only a service principal should have access to these environments and therefore all deployments must be executed through the service principal identity by using CI/CD pipelines. To summarize, in the development environment access rights should be provided to a service principal AND user identities and in higher environments access rights should only be provided to a service principal identity.

To be able to create resources and role assignments between resources within the Data Product resource group, `Contributor` and `User Access Administrator` rights must be provided. This will allow the teams to create and control services within their environment within the [boundaries of Azure Policy](#azure-policies). As Data Management & Analytics Scenario recommends the usage of private endpoints to overcome the data exfiltration risk and as other connectivity options should be blocked by the Azure Platform team via policies, Data Product teams will require access rights to the shared virtual network of a Data Landing Zone to be able to successfully setup the required network connectivity for the services they are planning to use. To follow the least privilege principle, overcome conflicts between different Data Product teams and have a clear separation of teams, ESA proposes to create a dedicated subnet per Data Product team and create a `Network Contributor` role assignment to that subnet (child resource scope). This role assignment allows the teams to join the subnet using private endpoints.
These two first role assignments will enable self-service deployment of data services within these environments. To address the cost management concern, organizations should add a cost centre tag to the resource groups to enable cross-charging and distributed cost ownership. This raises awareness within the teams and enforces them to make the right decisions with respect to required SKUs and service tiers.

To also enable self-service use of other shared resources within the Data Landing Zone, few additional role assignments are required. If access to a Databricks environment is required, organizations should use the [SCIM Synch from AAD](https://docs.microsoft.com/en-us/azure/databricks/administration-guide/users-groups/scim/aad) to provide access. This is important, as this mechanism automatically synchs users and groups from AAD to the Databricks data plane and also automatically removes access rights when an individual leaves the organization or business. This may not be the case, if separate user accounts are used in Aure Databricks. Data Product teams should be added to the Databricks workspace in the `shared-product-rg`, whereas Data Integration teams should be added to the Databricks workspace in the `shared-integration-rg`. Within Azure Databricks, the Data Product teams should be given `Can Restart` access rights to a predefined cluster to be able to run workloads within the workspace.

In order to encourage all Data Product and Data Integration teams to use the shared Data Lakes within a Data Landing Zone, access must be simple and should not create blockers when implementing data driven solutions within the Data Landing Zone. Some services within Azure require an Azure RBAC role assignment instead of access rights on the ACL layer of the storage account. This includes Synapse, the Event Hub or IoT Hub data capture features and a few other services. Hence, a dedicated container should be created for the respective Data Product and Data Integration teams on the shared Data Lake accounts. A Data Product team will get a container provided on the workspace storage account, whereas the Data Integration teams will get a container on the Raw as well as on the enriched & curated storage account.  

The individual teams will also require access to the central Purview account to discover data assets within the respective Data Landing Zones. Therefore, the teams will have to be added as `Data Reader` to the Purview top-level collection. In addition, the teams will in most cases require the option to edit catalogued data assets that they are owning in order to provide additional details such as contact details of data owners and experts as well as more granular details about what columns within a dataset describe and what information they are including. To achieve this, an organization should create a sub-collection per Data Landing Zone below the top-level collection. Within the Data Landing Zone sub-collections, additional sub-collection per Data Product or Data Integration should be created to which teams should be added as `Collection Admin`. This will also give them the flexibility to add their own custom data sources to the data catalogue and define their own scans based on their requirements.

### Access to other resources

Outside of Azure, Data Product and Data Integration teams will also require access to a repository to store code artifacts, collaborate effectively and roll out updates and changes consistently via CI/CD to higher environments. In addition, a project board should be provided to allow for agile development, sprint planning, tracking of tasks and as well as user feedback and feature requests.

Lastly, the CI/CD automation will require setting up a connection to Azure which is done in most services via service principles. Hence, teams will require access to a service principle to achieve automation within their project.

### Data Product Reference Patterns

When onboarding a Data Product or Data Integration team onto a Data Landing Zone, the team will be granted access to their dedicated resource group, subnet as well as the shared resources. From this point in time, the ownership of the environment is handed over to the Data Product or Data Integration team respectively. These teams have to take over responsibility from an end-to-end implementation as well as cost ownership perspective.

To simplify the way to get started and reduce the lead time to create an environment for a specific use-case, organizations can provide Data Product reference patterns internally. These reference implementations consist of the Infrastructure as Code (IaC) definitions to successfully create a set of services for a specific use case such as batch data processing, streaming data processing or data science and demonstrate a path to success. Potentially, these patterns also include generic application code that can be used as a baseline when implementing data solutions. Data Product reference patterns may vary between organizations and highly depend on the utilized tools and common and repeatedly used data implementation patterns across Data Landing Zones. Data Management & Analytics Scenario also provides a set of curated Data Product reference designs that can be used as baseline and that can be further enhanced by enterprises depending on their requirements. These can be found here:

- [Data Product Batch](https://github.com/Azure/data-product-batch)
- [Data Product Streaming](https://github.com/Azure/data-product-streaming)
- [Data Product Analytics](https://github.com/Azure/data-product-analytics)

Additional automation can be used to further reduce any potential friction points and automate even the initial deployment of the pattern for Data Product or Data Integration teams. For more details, please take a look at [this article](https://docs.microsoft.com/en-us/azure/cloud-adoption-framework/scenarios/data-management/eslz-platform-automation-and-devops).

Ultimately, the goal should be to hand over these reference implementations to the Data Product and Data Integration teams, as they should own the overall codebase of their solution. Additional abstraction layers such as Azure Template Specs are also an option, but just increase the number of friction points as required changes again need to be requested from a central team that owns and maintains these resources. The central team then needs to take an action to get the changes tested and released. Additionally, a more complex release management process may be required to not impact other consumers of the Template Spec. Lastly, the templates will become more and more complex over time as each team may require different parameters to be exposed to apply certain changes within the template. Hence, handing over the reference patterns is the easiest and most effective solution, since this allows the Data Product teams to make the necessary changes, if they need to. Exposing these teams to the concept of IaC is a good approach that may take some time but ultimately will result in better engineering practices across the data platform.
